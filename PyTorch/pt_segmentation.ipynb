{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/oem/.cache/torch/hub/pytorch_vision_v0.6.0\n",
      "Using cache found in /home/oem/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    }
   ],
   "source": [
    "# # Converting a Segmentation Model via CoreML -- https://developer.apple.com/videos/play/tech-talks/10154\n",
    "\n",
    "# ### Imports\n",
    "\n",
    "import urllib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import json\n",
    "\n",
    "from torchvision import transforms\n",
    "import coremltools as ct\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# ### Load Sample Model and Image\n",
    "\n",
    "# Load model\n",
    "model = torch.hub.load('pytorch/vision:v0.6.0', 'deeplabv3_resnet101', pretrained=True).eval()\n",
    "# Load sample image\n",
    "input_image = Image.open(\"dog_and_cat.jpg\")\n",
    "input_image = input_image.resize((224, 224))\n",
    "\n",
    "# ### Image Preprocessing\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "input_tensor = to_tensor(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "\n",
    "# ### Trace the Model with PyTorch\n",
    "\n",
    "# ### Wrap the Model to Allow Tracing\n",
    "\n",
    "class WrappedDeeplabv3Resnet101(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(WrappedDeeplabv3Resnet101, self).__init__()\n",
    "        self.model = torch.hub.load('pytorch/vision:v0.6.0', 'deeplabv3_resnet101', pretrained=True).eval()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        res = self.model(x)\n",
    "        x = res[\"out\"]\n",
    "        return x\n",
    "\n",
    "\n",
    "# ### Trace the Wrapped Model\n",
    "\n",
    "traceable_model = WrappedDeeplabv3Resnet101().eval()\n",
    "trace = torch.jit.trace(traceable_model, input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting PyTorch Frontend ==> MIL Ops: 100%|█████████▉| 844/845 [00:00<00:00, 5522.39 ops/s]\n",
      "Running MIL frontend_pytorch pipeline: 100%|██████████| 5/5 [00:00<00:00, 268.93 passes/s]\n",
      "Running MIL default pipeline: 100%|██████████| 56/56 [00:00<00:00, 60.48 passes/s] \n",
      "Running MIL backend_neuralnetwork pipeline: 100%|██████████| 8/8 [00:00<00:00, 455.68 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 944/944 [00:02<00:00, 341.83 ops/s] \n"
     ]
    }
   ],
   "source": [
    "# ### Convert to Core ML \n",
    "\n",
    "# Define input\n",
    "_input = ct.ImageType(\n",
    "    name=\"input_1\", \n",
    "    shape=input_batch.shape, \n",
    "    bias=[-0.485/0.229,-0.456/0.224,-0.406/0.225], \n",
    "    scale= 1./(255*0.226)\n",
    ")\n",
    "\n",
    "# Convert model\n",
    "mlmodel = ct.convert(\n",
    "    trace,\n",
    "    inputs=[_input],\n",
    ")\n",
    "\n",
    "\n",
    "# ### Set the Model Metadata\n",
    "\n",
    "labels_json = {\"labels\": [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"board\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningTable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedPlant\", \"sheep\", \"sofa\", \"train\", \"tvOrMonitor\"]}\n",
    "\n",
    "mlmodel.type = 'imageSegmenter'\n",
    "mlmodel.user_defined_metadata['com.apple.coreml.model.preview.params'] = json.dumps(labels_json)\n",
    "\n",
    "\n",
    "# ### Save the Model for Visualization\n",
    "\n",
    "mlmodel.save(\"SegmentationModel.mlmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
